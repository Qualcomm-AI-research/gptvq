#!/bin/bash

# Ensure PYTHONPATH points to the root gptvq directory

python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 256 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 512 --codebook-bitwidth 8 --quantize-per-codebook --vq-scaling-blocksize 32 $LLAMA1_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 128 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 256 --codebook-bitwidth 8 --quantize-per-codebook --vq-scaling-blocksize 32 $LLAMA1_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 1 --groupsize 512 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 1 --groupsize 1024 --codebook-bitwidth 8 --quantize-per-codebook --vq-scaling-blocksize 32 $LLAMA1_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 1 --groupsize 1024 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 1 --groupsize 2048 --codebook-bitwidth 8 --quantize-per-codebook --vq-scaling-blocksize 32 $LLAMA1_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 1024 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 2048 --codebook-bitwidth 8 --quantize-per-codebook --vq-scaling-blocksize 32 $LLAMA1_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 512 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 1024 --codebook-bitwidth 8 --quantize-per-codebook --vq-scaling-blocksize 32 $LLAMA1_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 2 --groupsize 4096 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 2 --groupsize 8192 --codebook-bitwidth 8 --quantize-per-codebook --vq-scaling-blocksize 32 $LLAMA1_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 2 --groupsize 16384 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 2 --groupsize 32768 --codebook-bitwidth 8 --quantize-per-codebook --vq-scaling-blocksize 32 $LLAMA1_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 256 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 512 --codebook-bitwidth 8 --quantize-per-codebook --vq-scaling-blocksize 32 $LLAMA2_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 128 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 256 --codebook-bitwidth 8 --quantize-per-codebook --vq-scaling-blocksize 32 $LLAMA2_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 1 --groupsize 512 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 1 --groupsize 1024 --codebook-bitwidth 8 --quantize-per-codebook --vq-scaling-blocksize 32 $LLAMA2_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 1 --groupsize 1024 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 1 --groupsize 2048 --codebook-bitwidth 8 --quantize-per-codebook --vq-scaling-blocksize 32 $LLAMA2_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 1024 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 2048 --codebook-bitwidth 8 --quantize-per-codebook --vq-scaling-blocksize 32 $LLAMA2_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 512 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 1024 --codebook-bitwidth 8 --quantize-per-codebook --vq-scaling-blocksize 32 $LLAMA2_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 2 --groupsize 4096 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 2 --groupsize 8192 --codebook-bitwidth 8 --quantize-per-codebook --vq-scaling-blocksize 32 $LLAMA2_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 2 --groupsize 16384 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 2 --groupsize 32768 --codebook-bitwidth 8 --quantize-per-codebook --vq-scaling-blocksize 32 $LLAMA2_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 256 --codebook-bitwidth 8 --quantize-per-codebook --is-mistral $MISTRAL_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 512 --codebook-bitwidth 8 --quantize-per-codebook --vq-scaling-blocksize 32 --is-mistral $MISTRAL_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 128 --codebook-bitwidth 8 --quantize-per-codebook --is-mistral $MISTRAL_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 256 --codebook-bitwidth 8 --quantize-per-codebook --vq-scaling-blocksize 32 --is-mistral $MISTRAL_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 1 --groupsize 512 --codebook-bitwidth 8 --quantize-per-codebook --is-mistral $MISTRAL_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 1 --groupsize 1024 --codebook-bitwidth 8 --quantize-per-codebook --vq-scaling-blocksize 32 --is-mistral $MISTRAL_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 1 --groupsize 1024 --codebook-bitwidth 8 --quantize-per-codebook --is-mistral $MISTRAL_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 1 --groupsize 2048 --codebook-bitwidth 8 --quantize-per-codebook --vq-scaling-blocksize 32 --is-mistral $MISTRAL_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 1024 --codebook-bitwidth 8 --quantize-per-codebook --is-mistral $MISTRAL_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 2048 --codebook-bitwidth 8 --quantize-per-codebook --vq-scaling-blocksize 32 --is-mistral $MISTRAL_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 512 --codebook-bitwidth 8 --quantize-per-codebook --is-mistral $MISTRAL_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 1024 --codebook-bitwidth 8 --quantize-per-codebook --vq-scaling-blocksize 32 --is-mistral $MISTRAL_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 2 --groupsize 4096 --codebook-bitwidth 8 --quantize-per-codebook --is-mistral $MISTRAL_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 2 --groupsize 8192 --codebook-bitwidth 8 --quantize-per-codebook --vq-scaling-blocksize 32 --is-mistral $MISTRAL_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 2 --groupsize 16384 --codebook-bitwidth 8 --quantize-per-codebook --is-mistral $MISTRAL_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 2 --groupsize 32768 --codebook-bitwidth 8 --quantize-per-codebook --vq-scaling-blocksize 32 --is-mistral $MISTRAL_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 256 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 512 --codebook-bitwidth 8 --quantize-per-codebook --vq-scaling-blocksize 32 $LLAMA2_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 128 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 256 --codebook-bitwidth 8 --quantize-per-codebook --vq-scaling-blocksize 32 $LLAMA2_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 1 --groupsize 512 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 1 --groupsize 1024 --codebook-bitwidth 8 --quantize-per-codebook --vq-scaling-blocksize 32 $LLAMA2_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 1 --groupsize 1024 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 1 --groupsize 2048 --codebook-bitwidth 8 --quantize-per-codebook --vq-scaling-blocksize 32 $LLAMA2_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 1024 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 2048 --codebook-bitwidth 8 --quantize-per-codebook --vq-scaling-blocksize 32 $LLAMA2_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 512 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 1024 --codebook-bitwidth 8 --quantize-per-codebook --vq-scaling-blocksize 32 $LLAMA2_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 2 --groupsize 4096 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 2 --groupsize 8192 --codebook-bitwidth 8 --quantize-per-codebook --vq-scaling-blocksize 32 $LLAMA2_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 2 --groupsize 16384 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 2 --groupsize 32768 --codebook-bitwidth 8 --quantize-per-codebook --vq-scaling-blocksize 32 $LLAMA2_13B_PATH wikitext2
