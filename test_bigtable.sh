#!/bin/bash

# Ensure PYTHONPATH points to the root gptvq directory

python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 256 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 512 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 128 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 256 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 1 --groupsize 512 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 1 --groupsize 1024 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 1 --groupsize 1024 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 1 --groupsize 2048 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 2048 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 4096 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 1024 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 2048 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 2 --groupsize 8192 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 2 --groupsize 16384 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 2 --groupsize 32768 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 2 --groupsize 65536 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 4 --groupsize 65536 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 4 --groupsize 32768 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 4 --groupsize 65536 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 256 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 512 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 128 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 256 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 1 --groupsize 512 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 1 --groupsize 1024 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 1 --groupsize 1024 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 1 --groupsize 2048 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 2048 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 4096 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 1024 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 2048 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 2 --groupsize 8192 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 2 --groupsize 16384 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 2 --groupsize 32768 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 2 --groupsize 65536 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 4 --groupsize 65536 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 4 --groupsize 32768 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 4 --groupsize 65536 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 256 --model-type mistral --codebook-bitwidth 8 --quantize-per-codebook $MISTRAL_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 512 --vq-scaling-blocksize 64 --model-type mistral --codebook-bitwidth 8 --quantize-per-codebook $MISTRAL_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 128 --model-type mistral --codebook-bitwidth 8 --quantize-per-codebook $MISTRAL_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 256 --vq-scaling-blocksize 64 --model-type mistral --codebook-bitwidth 8 --quantize-per-codebook $MISTRAL_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 1 --groupsize 512 --model-type mistral --codebook-bitwidth 8 --quantize-per-codebook $MISTRAL_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 1 --groupsize 1024 --vq-scaling-blocksize 64 --model-type mistral --codebook-bitwidth 8 --quantize-per-codebook $MISTRAL_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 1 --groupsize 1024 --model-type mistral --codebook-bitwidth 8 --quantize-per-codebook $MISTRAL_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 1 --groupsize 2048 --vq-scaling-blocksize 64 --model-type mistral --codebook-bitwidth 8 --quantize-per-codebook $MISTRAL_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 2048 --model-type mistral --codebook-bitwidth 8 --quantize-per-codebook $MISTRAL_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 4096 --vq-scaling-blocksize 64 --model-type mistral --codebook-bitwidth 8 --quantize-per-codebook $MISTRAL_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 1024 --model-type mistral --codebook-bitwidth 8 --quantize-per-codebook $MISTRAL_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 2048 --vq-scaling-blocksize 64 --model-type mistral --codebook-bitwidth 8 --quantize-per-codebook $MISTRAL_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 2 --groupsize 8192 --model-type mistral --codebook-bitwidth 8 --quantize-per-codebook $MISTRAL_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 2 --groupsize 16384 --vq-scaling-blocksize 64 --model-type mistral --codebook-bitwidth 8 --quantize-per-codebook $MISTRAL_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 2 --groupsize 32768 --model-type mistral --codebook-bitwidth 8 --quantize-per-codebook $MISTRAL_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 2 --groupsize 65536 --vq-scaling-blocksize 64 --model-type mistral --codebook-bitwidth 8 --quantize-per-codebook $MISTRAL_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 4 --groupsize 65536 --model-type mistral --codebook-bitwidth 8 --quantize-per-codebook $MISTRAL_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 4 --groupsize 32768 --model-type mistral --codebook-bitwidth 8 --quantize-per-codebook $MISTRAL_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 4 --groupsize 65536 --vq-scaling-blocksize 64 --model-type mistral --codebook-bitwidth 8 --quantize-per-codebook $MISTRAL_7B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 256 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 512 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 128 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 256 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 1 --groupsize 512 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 1 --groupsize 1024 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 1 --groupsize 1024 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 1 --groupsize 2048 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 2048 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 4096 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 1024 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 2048 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 2 --groupsize 8192 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 2 --groupsize 16384 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 2 --groupsize 32768 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 2 --groupsize 65536 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 4 --groupsize 65536 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 4 --groupsize 32768 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 4 --groupsize 65536 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 256 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 512 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 128 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 256 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 1 --groupsize 512 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 1 --groupsize 1024 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 1 --groupsize 1024 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 1 --groupsize 2048 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 2048 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 4096 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 1024 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 2048 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 2 --groupsize 8192 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 2 --groupsize 16384 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 2 --groupsize 32768 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 2 --groupsize 65536 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 4 --groupsize 65536 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 4 --groupsize 32768 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 4 --groupsize 65536 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_13B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 256 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_30B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 512 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_30B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 128 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_30B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 256 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_30B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 1 --groupsize 512 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_30B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 1 --groupsize 1024 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_30B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 1 --groupsize 1024 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_30B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 1 --groupsize 2048 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_30B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 2048 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_30B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 4096 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_30B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 1024 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_30B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 2048 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_30B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 2 --groupsize 8192 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_30B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 2 --groupsize 16384 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_30B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 2 --groupsize 32768 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_30B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 2 --groupsize 65536 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_30B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 4 --groupsize 65536 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_30B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 4 --groupsize 32768 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_30B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 4 --groupsize 65536 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_30B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 256 --model-type mixtral --codebook-bitwidth 8 --quantize-per-codebook $MIXTRAL_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 512 --vq-scaling-blocksize 64 --model-type mixtral --codebook-bitwidth 8 --quantize-per-codebook $MIXTRAL_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 128 --model-type mixtral --codebook-bitwidth 8 --quantize-per-codebook $MIXTRAL_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 256 --vq-scaling-blocksize 64 --model-type mixtral --codebook-bitwidth 8 --quantize-per-codebook $MIXTRAL_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 1 --groupsize 512 --model-type mixtral --codebook-bitwidth 8 --quantize-per-codebook $MIXTRAL_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 1 --groupsize 1024 --vq-scaling-blocksize 64 --model-type mixtral --codebook-bitwidth 8 --quantize-per-codebook $MIXTRAL_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 1 --groupsize 1024 --model-type mixtral --codebook-bitwidth 8 --quantize-per-codebook $MIXTRAL_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 1 --groupsize 2048 --vq-scaling-blocksize 64 --model-type mixtral --codebook-bitwidth 8 --quantize-per-codebook $MIXTRAL_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 2048 --model-type mixtral --codebook-bitwidth 8 --quantize-per-codebook $MIXTRAL_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 4096 --vq-scaling-blocksize 64 --model-type mixtral --codebook-bitwidth 8 --quantize-per-codebook $MIXTRAL_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 1024 --model-type mixtral --codebook-bitwidth 8 --quantize-per-codebook $MIXTRAL_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 2048 --vq-scaling-blocksize 64 --model-type mixtral --codebook-bitwidth 8 --quantize-per-codebook $MIXTRAL_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 2 --groupsize 8192 --model-type mixtral --codebook-bitwidth 8 --quantize-per-codebook $MIXTRAL_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 2 --groupsize 16384 --vq-scaling-blocksize 64 --model-type mixtral --codebook-bitwidth 8 --quantize-per-codebook $MIXTRAL_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 2 --groupsize 32768 --model-type mixtral --codebook-bitwidth 8 --quantize-per-codebook $MIXTRAL_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 2 --groupsize 65536 --vq-scaling-blocksize 64 --model-type mixtral --codebook-bitwidth 8 --quantize-per-codebook $MIXTRAL_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 4 --groupsize 65536 --model-type mixtral --codebook-bitwidth 8 --quantize-per-codebook $MIXTRAL_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 4 --groupsize 32768 --model-type mixtral --codebook-bitwidth 8 --quantize-per-codebook $MIXTRAL_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 4 --groupsize 65536 --vq-scaling-blocksize 64 --model-type mixtral --codebook-bitwidth 8 --quantize-per-codebook $MIXTRAL_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 256 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_65B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 512 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_65B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 128 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_65B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 256 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_65B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 1 --groupsize 512 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_65B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 1 --groupsize 1024 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_65B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 1 --groupsize 1024 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_65B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 1 --groupsize 2048 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_65B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 2048 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_65B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 4096 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_65B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 1024 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_65B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 2048 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_65B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 2 --groupsize 8192 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_65B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 2 --groupsize 16384 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_65B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 2 --groupsize 32768 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_65B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 2 --groupsize 65536 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_65B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 4 --groupsize 65536 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_65B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 4 --groupsize 32768 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_65B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 4 --groupsize 65536 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA1_65B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 256 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_70B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 512 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_70B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 128 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_70B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 1 --groupsize 256 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_70B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 1 --groupsize 512 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_70B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 1 --groupsize 1024 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_70B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 1 --groupsize 1024 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_70B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 1 --groupsize 2048 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_70B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 2048 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_70B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 4096 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_70B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 1024 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_70B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 2 --groupsize 2048 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_70B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 2 --groupsize 8192 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_70B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 3 --vq-dim 2 --groupsize 16384 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_70B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 2 --groupsize 32768 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_70B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 4 --vq-dim 2 --groupsize 65536 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_70B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 4 --groupsize 65536 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_70B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 4 --groupsize 32768 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_70B_PATH wikitext2
python llama.py --columns-per-group 256 --use-vq --kmeans-iters 100 --kmeans-init-method mahalanobis --hessian-weighted-lookups --include-m-step --wbits 2 --vq-dim 4 --groupsize 65536 --vq-scaling-blocksize 64 --codebook-bitwidth 8 --quantize-per-codebook $LLAMA2_70B_PATH wikitext2
